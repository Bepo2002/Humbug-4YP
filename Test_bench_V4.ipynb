{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bepo2002/Humbug-4YP/blob/main/Test_bench_V4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Bench V4\n",
        "\n",
        "### Test bench V3 with genus classification"
      ],
      "metadata": {
        "id": "MqfTwjZRwlIl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup env"
      ],
      "metadata": {
        "id": "WUFtTe1cwrRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install visualkeras\n",
        "%pip install pycodestyle pycodestyle_magic\n",
        "%pip install flake8\n",
        "%pip install -q -U tensorboard-plugin-profile\n",
        "%load_ext pycodestyle_magic\n",
        "%pip install scikit-plot"
      ],
      "metadata": {
        "id": "SHi6tft_XogH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e97e965-ed87-4cc4-d27f-3b87e1944ec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: visualkeras in /usr/local/lib/python3.10/dist-packages (0.0.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from visualkeras) (9.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.10/dist-packages (from visualkeras) (1.25.2)\n",
            "Requirement already satisfied: aggdraw>=1.3.11 in /usr/local/lib/python3.10/dist-packages (from visualkeras) (1.3.18.post0)\n",
            "Requirement already satisfied: pycodestyle in /usr/local/lib/python3.10/dist-packages (2.11.1)\n",
            "Requirement already satisfied: pycodestyle_magic in /usr/local/lib/python3.10/dist-packages (0.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JELY6v0CAAxH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import wavfile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from IPython.display import Audio\n",
        "import matplotlib.colors as mclr\n",
        "import librosa\n",
        "import visualkeras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import EarlyStopping\n",
        "from pathlib import Path\n",
        "from time import strftime\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import scikitplot as skplt\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "import csv\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "9J6Rl5EmNMhp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLzGTr4r-osn"
      },
      "outputs": [],
      "source": [
        "# Finds specific sound in zip and extracts it\n",
        "def extract_sound(filename, silent=False):\n",
        "    zip_files = ['./drive/MyDrive/4YP/train.zip',\n",
        "                 './drive/MyDrive/4YP/dev.zip']\n",
        "    folders = ['train/', 'dev/a/', 'dev/b/']\n",
        "    dest_dir = './drive/MyDrive/4YP/Data'\n",
        "    filename_to_extract = str(filename) + '.wav'\n",
        "\n",
        "    for zip_path in zip_files:\n",
        "        for folder in folders:\n",
        "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "                filename_to_extract = folder + filename_to_extract\n",
        "                if filename_to_extract in zip_ref.namelist():\n",
        "                    zip_ref.extract(filename_to_extract, dest_dir)\n",
        "                    if not silent:\n",
        "                        print(f\"{filename_to_extract} has been extracted\",\n",
        "                              f\"to {dest_dir}\")\n",
        "                    final = './drive/MyDrive/4YP/Data/' + filename_to_extract\n",
        "                    return wavfile.read(final)\n",
        "    print(f\"{filename_to_extract} not found in any of the provided ZIP files.\")\n",
        "\n",
        "\n",
        "# Read in .csv\n",
        "def csv_read():\n",
        "    metadata = pd.read_csv('./drive/MyDrive/4YP/Data/humbugdb_zenodo_edited.csv')\n",
        "    metadata = metadata.set_index('id')\n",
        "    return metadata\n",
        "\n",
        "\n",
        "def gaussian(x, mu, sigma):\n",
        "    return np.exp(-((x - mu)**2) / (2 * sigma**2))\n",
        "\n",
        "\n",
        "# Normalise audio\n",
        "def normalize_audio(audio, target_dBFS=0):\n",
        "    # Calculate the current dBFS of the audio\n",
        "    rms = np.sqrt(np.mean(np.square(audio)))\n",
        "    current_dBFS = 20 * np.log10(rms)\n",
        "\n",
        "    # Calculate the required gain to achieve the target dBFS\n",
        "    gain = target_dBFS - current_dBFS\n",
        "\n",
        "    # Apply gain to the audio data\n",
        "    normalized_audio = audio * (10 ** (gain / 20))\n",
        "\n",
        "    return normalized_audio\n",
        "\n",
        "\n",
        "def progress_bar(progress, total):\n",
        "    percent = 100 * (progress / float(total))\n",
        "    bar = '#' * int(percent) + '-' * (100 - int(percent))\n",
        "    print(\"[%s] %d%%\" % (bar, percent))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFZiwS0x-26K"
      },
      "outputs": [],
      "source": [
        "# Full function for generating noise + mosquito\n",
        "def long_sound_gen(mos_num, SNR=1, silent=False):\n",
        "    metadata = csv_read()\n",
        "\n",
        "    # Choose a long noise sound\n",
        "    subset = metadata[(metadata['sound_type'] == 'background') &\n",
        "                      (metadata['length'] > 10) &\n",
        "                      (metadata['sample_rate'] == 44100) &\n",
        "                      (metadata['clean'] == \"Y\")]\n",
        "\n",
        "    noise_id = subset.sample(random_state=np.random.randint(0,100)).index.values[0]\n",
        "    print(\"noise_id: \", noise_id)\n",
        "\n",
        "    # Extract the sound wave and find samplerate\n",
        "    n_samplerate, noise = extract_sound(noise_id, silent)\n",
        "\n",
        "    # Normalise\n",
        "    noise = normalize_audio(noise/100)\n",
        "\n",
        "    # Choose a shorter mosquito sound\n",
        "    subset = metadata[(metadata['sound_type'] == 'mosquito') &\n",
        "                      (metadata['length'] < 10) &\n",
        "                      (metadata['length'] > 1) &\n",
        "                      (metadata['sample_rate'] == 44100)]\n",
        "\n",
        "    chosen = subset.sample(random_state=np.random.randint(0,100))\n",
        "    mos_id = chosen.index.values[0]\n",
        "    audio_spec = chosen.species.values[0]\n",
        "    print(\"mos_id: \", mos_id)\n",
        "    print(\"Species: \", audio_spec)\n",
        "\n",
        "    # Import the sound wave and find samplerate\n",
        "    samplerate, data = extract_sound(mos_id, silent)\n",
        "\n",
        "    # Normalise\n",
        "    data = normalize_audio(data/100)\n",
        "\n",
        "    # Add sound to random time in noise\n",
        "    # Initilise vectors to store new audio and whether each sample\n",
        "    # is from mosquito or noise\n",
        "    new_audio = np.zeros(noise.size)\n",
        "    sound_cat = np.zeros(noise.size)\n",
        "    old_audio = np.zeros(noise.size)\n",
        "\n",
        "    for i in range(0, mos_num):\n",
        "\n",
        "        # Choose a 'time' to put the middle of mosquito sound wave\n",
        "        mosquito_time = np.random.randint(data.size//2,\n",
        "                                          high=noise.size-data.size//2,\n",
        "                                          dtype=int)\n",
        "        if not silent:\n",
        "            print(\"Adding mosquito noise at \",\n",
        "                  str(round(mosquito_time/samplerate, 3)), \"s\")\n",
        "\n",
        "        # Put wave into long array\n",
        "        new_audio[mosquito_time - data.size//2:(mosquito_time - data.size//2)+data.size] = data\n",
        "        sound_cat[mosquito_time - data.size//2:mosquito_time + data.size//2] = 1\n",
        "\n",
        "        # Generate gaussian in same place as mos audio\n",
        "        x = np.linspace(0, noise.size, noise.size, dtype=int)\n",
        "        y = gaussian(x, mosquito_time, data.size/6)\n",
        "\n",
        "        # Multiply to apply gaussian to audio\n",
        "        old_audio = y*new_audio + old_audio\n",
        "\n",
        "    # Add faded mosquito sound to background noise\n",
        "    full_audio = noise/SNR + old_audio\n",
        "\n",
        "    return full_audio, samplerate, sound_cat, audio_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suFDTsH__H20"
      },
      "outputs": [],
      "source": [
        "# Convert numbers to 0 or 1 depending on threshold\n",
        "def binarize(input_array, thresh=0):\n",
        "    output_array = np.zeros(len(input_array))\n",
        "    for i in range(len(input_array)):\n",
        "        if input_array[i] > thresh:\n",
        "            output_array[i] = 1\n",
        "        else:\n",
        "            output_array[i] = 0\n",
        "\n",
        "    return output_array"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chops the audio clip into sections and creates a vector of clips\n",
        "def chop_chop(audio, samplerate, seconds_per_clip=1):\n",
        "    # Choose bin size (default 1 second clip)\n",
        "    bin_size = int(samplerate*seconds_per_clip)\n",
        "\n",
        "    # Reshape Data\n",
        "    rows = int(audio.size/bin_size)\n",
        "    audio = audio[:rows*bin_size]\n",
        "    audio = np.reshape(audio, (rows, bin_size))\n",
        "    audio = np.concatenate((audio, np.zeros((rows, 1))), axis=1)\n",
        "    return audio"
      ],
      "metadata": {
        "id": "43VVo2sSYV7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_images(images, y_true, y_pred, num_images=10):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.suptitle(\"Mislabelled images:\")\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(5, 5, i+1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        plt.imshow(images[i], cmap=plt.cm.binary)\n",
        "        plt.xlabel(f\"True: {y_true[i]}, Pred: {y_pred[i]}\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "DCRbh2N_PcXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## More helper functions"
      ],
      "metadata": {
        "id": "YuZbDXwZxt_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_training_data(mosquitoness=1, SNR=2, chop_size=3,\n",
        "                           silent=False):\n",
        "    # Create the long mixed audio (mosquito + noise)\n",
        "    full_audio, samplerate, sound_cat, audio_spec = long_sound_gen(mosquitoness,\n",
        "                                                       SNR, silent)\n",
        "\n",
        "    # Chop audio into X second clips\n",
        "    chopped_audio = chop_chop(full_audio, samplerate, chop_size)\n",
        "\n",
        "    # Create an average 'mosquitoness' of each clip\n",
        "    chopped_cat = chop_chop(sound_cat, samplerate, chop_size)\n",
        "    av_chopped_cat = np.mean(chopped_cat, axis=1)\n",
        "\n",
        "    # Generate spectrogram for each clip\n",
        "    mel_spect = librosa.feature.melspectrogram(y=chopped_audio[0],\n",
        "                                               sr=samplerate, n_fft=1024,\n",
        "                                               hop_length=256)\n",
        "    spectro = np.zeros((len(chopped_audio), 128, mel_spect.shape[1]))\n",
        "    for i in range(0, len(chopped_audio)):\n",
        "        mel_spect = librosa.feature.melspectrogram(y=chopped_audio[i],\n",
        "                                                   sr=samplerate, n_fft=1024,\n",
        "                                                   hop_length=256)\n",
        "        mel_spect = librosa.power_to_db(mel_spect, ref=np.max)\n",
        "        mel_spect = (mel_spect + 80) / 80\n",
        "        spectro[i] = mel_spect\n",
        "\n",
        "    # Returns a number of seconds in audio x n_mfcc matrix and an array\n",
        "    # of sound category (how much mosquito) in each X second chop\n",
        "    return spectro, av_chopped_cat, audio_spec"
      ],
      "metadata": {
        "id": "tVjL2K_DbnDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multiple_training_data(amount_of_audio, mosquitoness=2, SNR=2,\n",
        "                           chop_size=3, silent=False):\n",
        "    X, Y, audio_spec = generate_training_data(mosquitoness, SNR, chop_size,\n",
        "                                  silent)\n",
        "    audio_specs = np.tile(audio_spec, len(Y))\n",
        "    for i in range(0, amount_of_audio-1):\n",
        "        specto, av_chopped_cat, audio_spec = generate_training_data(mosquitoness,\n",
        "                                                        SNR,\n",
        "                                                        chop_size, silent)\n",
        "        X = np.concatenate((X, specto))\n",
        "        Y = np.concatenate((Y, av_chopped_cat))\n",
        "        audio_specs = np.append(audio_specs, np.tile(audio_spec, len(av_chopped_cat)))\n",
        "        progress_bar(i + 1, amount_of_audio)\n",
        "    return X, Y, audio_specs"
      ],
      "metadata": {
        "id": "cJ5_XHm2eljm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_run_logdir(root_logdir=\"./drive/MyDrive/my_logs\", name=\"run_%Y_%m_%d_%H_%M_%S\"):\n",
        "    return Path(root_logdir) / strftime(name)"
      ],
      "metadata": {
        "id": "-ftHbxrnO9rP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Bench Function"
      ],
      "metadata": {
        "id": "xgGG3VzkxmeN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_bench(test_model, sound_count, mosquitoness, SNR, chop_size, thresh,\n",
        "               learning_rate, patient, name, kern=1):\n",
        "\n",
        "    tf.keras.utils.set_random_seed(42)\n",
        "\n",
        "    # Calculate the number of time bins to be generated per image\n",
        "    time_size = int(1+((44100*chop_size)/256))\n",
        "    print(\"Time size: \", time_size)\n",
        "\n",
        "\n",
        "    # Create the keras model\n",
        "    tf.keras.backend.clear_session()\n",
        "    if test_model == 1:\n",
        "        model = tf.keras.Sequential([\n",
        "            tf.keras.layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\",\n",
        "                                   input_shape=(128, time_size, 1)),\n",
        "            tf.keras.layers.MaxPooling2D(),\n",
        "            tf.keras.layers.Dropout(0.5),\n",
        "            tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\"),\n",
        "            tf.keras.layers.MaxPooling2D(),\n",
        "            tf.keras.layers.Dropout(0.5),\n",
        "            tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\"),\n",
        "            tf.keras.layers.MaxPooling2D(),\n",
        "            tf.keras.layers.Dropout(0.5),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(units=128, activation=\"relu\"),\n",
        "            tf.keras.layers.Dropout(0.5),\n",
        "            tf.keras.layers.Dense(units=1)\n",
        "        ])\n",
        "    else:\n",
        "        model = tf.keras.Sequential([\n",
        "            tf.keras.layers.Conv2D(filters=16, kernel_size=(128,kern),\n",
        "                                   activation=\"relu\",\n",
        "                                   input_shape=(128, time_size, 1)),\n",
        "            tf.keras.layers.MaxPooling2D(pool_size=(1, 2)),\n",
        "            tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=32, kernel_size=(1,3),\n",
        "                                   activation=\"relu\"),\n",
        "            tf.keras.layers.MaxPooling2D(pool_size=(1, 2)),\n",
        "            tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=64, kernel_size=(1,3),\n",
        "                                   activation=\"relu\"),\n",
        "            tf.keras.layers.MaxPooling2D(pool_size=(1, 2)),\n",
        "            tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(units=20, activation=\"relu\"),\n",
        "            tf.keras.layers.Dropout(0.5),\n",
        "            tf.keras.layers.Dense(units=1)\n",
        "        ])\n",
        "\n",
        "    #test_model_2.summary()\n",
        "    #visualkeras.layered_view(test_model_2, legend=True)\n",
        "\n",
        "\n",
        "    # Create train and dev/val set\n",
        "    print(\"----GENERATING DATA FOR TEST----\")\n",
        "    X, Y, audio_specs = multiple_training_data(sound_count, mosquitoness, SNR,\n",
        "                                  chop_size, silent=True)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"----BEFORE BINARISATION----\")\n",
        "    print(\"Mosquito Clips: \", np.count_nonzero(Y))\n",
        "    print(\"Background Clips: \", len(Y)-np.count_nonzero(Y))\n",
        "    print(\"Total: \", len(Y))\n",
        "\n",
        "    Y_bin = binarize(Y, thresh)\n",
        "    print(\"----AFTER BINARISATION----\")\n",
        "    print(\"Mosquito Clips: \", np.count_nonzero(Y_bin))\n",
        "    print(\"Background Clips: \", len(Y_bin)-np.count_nonzero(Y_bin))\n",
        "    print(\"Total: \", len(Y_bin), '\\n')\n",
        "    X_train, X_dev, y_train, y_dev, specs_train, specs_dev = train_test_split(X, Y_bin, audio_specs, test_size=0.2,\n",
        "                                                      random_state=42)\n",
        "    X_train = X_train.reshape(len(X_train), 128, -1, 1)\n",
        "    X_dev = X_dev.reshape(len(X_dev), 128, -1, 1)\n",
        "\n",
        "    print(\"Training set size: \", X_train.shape[0])\n",
        "    print(\"Validation set size: \", X_dev.shape[0])\n",
        "    print(\"\")\n",
        "    print(\"Input Shape: \", X_train.shape)\n",
        "    print(\"----TRAINING----\")\n",
        "\n",
        "    # Train model\n",
        "\n",
        "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                  optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor=\"val_loss\",\n",
        "                                   patience=patient,\n",
        "                                   verbose=1,\n",
        "                                   restore_best_weights=True)\n",
        "    run_logdir = get_run_logdir(name=name)  # e.g., my_logs/run_2022_08_01_17_25_59\n",
        "    tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir,\n",
        "                                                    profile_batch=(100, 200))\n",
        "    history = model.fit(X_train, y_train, epochs=100,\n",
        "                        validation_data=(X_dev, y_dev),\n",
        "                        callbacks=[tensorboard_cb])\n",
        "\n",
        "    # Evalute model performance\n",
        "\n",
        "    y_pred = model.predict(X_dev)\n",
        "\n",
        "    # Plotting of ROC curve\n",
        "    y_prob = 1 / (1 + np.exp(-y_pred))\n",
        "    y_prob = y_prob.flatten()\n",
        "    y_pred = y_prob.round().astype(int)\n",
        "    RocCurveDisplay.from_predictions(y_dev, y_prob)\n",
        "    plt.show()\n",
        "\n",
        "    # Species performance\n",
        "\n",
        "    correct = y_pred == y_dev\n",
        "\n",
        "    # Count the frequency of each class in both arrays\n",
        "    counts1 = Counter(specs_dev[correct])\n",
        "    counts2 = Counter(specs_dev)\n",
        "\n",
        "    print(counts1)\n",
        "    print(counts2)\n",
        "\n",
        "    # Get a combined set of keys from both counters to include all possible classes\n",
        "    all_classes = list(set(counts1.keys()) | set(counts2.keys()))\n",
        "\n",
        "    # Prepare frequencies, setting to 0 for classes that don't appear in one of the arrays\n",
        "    frequencies1 = [counts1[cls] for cls in all_classes]\n",
        "    frequencies2 = [counts2[cls] for cls in all_classes]\n",
        "\n",
        "    # Set the width of the bars\n",
        "    barWidth = 0.35\n",
        "\n",
        "    # Set position of bar on X axis\n",
        "    r1 = (np.arange(len(all_classes)))*2\n",
        "    r2 = [x + barWidth for x in r1]\n",
        "\n",
        "    # Make the plot\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.bar(r1, frequencies1, color='blue', width=barWidth, edgecolor='grey', label='Correct identification')\n",
        "    plt.bar(r2, frequencies2, color='red', width=barWidth, edgecolor='grey', label='Occurance in validation set')\n",
        "\n",
        "    # Add xticks on the middle of the group bars\n",
        "    plt.xlabel('Species', fontweight='bold')\n",
        "    plt.xticks([(r + barWidth/2)*2 for r in range(len(all_classes))], all_classes)\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title('Accuracy of mosquito detection by species')\n",
        "\n",
        "    # Specify the CSV file name\n",
        "    csv_file = 'species_correct.csv'\n",
        "\n",
        "    # Open the CSV file for writing\n",
        "    with open(csv_file, 'w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "\n",
        "        # Write the header\n",
        "        writer.writerow(['Species', 'Correct'])\n",
        "\n",
        "        # Write the counts\n",
        "        for item, count in counts1.items():\n",
        "            writer.writerow([item, count])\n",
        "\n",
        "    # Specify the CSV file name\n",
        "    csv_file = 'species_total.csv'\n",
        "\n",
        "    # Open the CSV file for writing\n",
        "    with open(csv_file, 'w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "\n",
        "        # Write the header\n",
        "        writer.writerow(['Species', 'Total'])\n",
        "\n",
        "        # Write the counts\n",
        "        for item, count in counts2.items():\n",
        "            writer.writerow([item, count])\n",
        "\n",
        "    # Create legend & Show graphic\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    correctly_classified_images = X_dev[correct]\n",
        "    incorrectly_classified_images = X_dev[~correct]\n",
        "    print(\"\")\n",
        "    print(\"----RESULTS----\")\n",
        "    print(\"Correct: \", len(correctly_classified_images))\n",
        "    print(\"Incorrect: \", len(incorrectly_classified_images))\n",
        "\n",
        "    true_labels = y_dev[~correct].astype(int)\n",
        "    predicted_labels = y_pred[~correct]\n",
        "\n",
        "    # Display first 10 incorrectly classified images\n",
        "    display_images(incorrectly_classified_images, true_labels, predicted_labels,\n",
        "                   num_images=min(25, len(incorrectly_classified_images)))\n",
        "\n",
        "    confusion = confusion_matrix(y_dev, y_pred)\n",
        "    true_pos = confusion[1][1]\n",
        "    true_neg = confusion[0][0]\n",
        "    false_pos = confusion[0][1]\n",
        "    false_neg = confusion[1][0]\n",
        "\n",
        "    print(\"True positive: \" + str(true_pos))\n",
        "    print(\"True negative: \" + str(true_neg))\n",
        "    print(\"False positive: \" + str(false_pos))\n",
        "    print(\"False negative: \" + str(false_neg))\n",
        "\n",
        "    sensitivity = (true_pos/(true_pos+false_neg)).round(3)\n",
        "    specificity = (true_neg/(true_neg+false_pos)).round(3)\n",
        "\n",
        "    print(\"Sensitivity: \" + str(sensitivity))\n",
        "    print(\"Specificity: \" + str(specificity))\n",
        "    print(\"Score: \" + str((sensitivity+specificity).round(3)))\n",
        "    disp = ConfusionMatrixDisplay(confusion,\n",
        "                                  display_labels=[\"Background\", \"Mosquito\"])\n",
        "    disp.plot()\n",
        "\n",
        "    return model, X_train, X_dev, y_train, y_dev, specs_train, specs_dev, y_pred"
      ],
      "metadata": {
        "id": "L7t0IsyVNaDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Working Code"
      ],
      "metadata": {
        "id": "YfV9QCNCP80Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Bench"
      ],
      "metadata": {
        "id": "DNYK9sFKeroA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the test bench\n",
        "comp_model, X_train, X_dev, y_train, y_dev, specs_train, specs_dev, y_pred = test_bench(test_model=1,\n",
        "                                                                                   sound_count=500,\n",
        "                                                                                   mosquitoness=1,\n",
        "                                                                                   SNR=1,\n",
        "                                                                                   chop_size=3,\n",
        "                                                                                   thresh=0.1,\n",
        "                                                                                   learning_rate=0.0005,\n",
        "                                                                                   patient=10,\n",
        "                                                                                   name=\"gen1\")"
      ],
      "metadata": {
        "id": "OcPIPTXE9wdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mosquito classifier (Binary)"
      ],
      "metadata": {
        "id": "yJSCxrPveuAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate training set from only positive anopheles and culex\n",
        "\n",
        "y_train_n = []\n",
        "genera_train = []\n",
        "index = []\n",
        "\n",
        "# Only include if 1 and \"an\" or \"culex\"\n",
        "for i in range(len(y_train)):\n",
        "    genus = specs_train[i].partition(' ')[0]\n",
        "    cat = y_train[i]\n",
        "    if cat:\n",
        "        if genus == \"an\":\n",
        "            index.append(True)\n",
        "            y_train_n.append(0)\n",
        "            genera_train.append(\"anopheles\")\n",
        "        elif genus == \"culex\":\n",
        "            index.append(True)\n",
        "            y_train_n.append(1)\n",
        "            genera_train.append(\"culex\")\n",
        "        else:\n",
        "            index.append(False)\n",
        "    else:\n",
        "        index.append(False)\n",
        "\n",
        "X_train_n = X_train[index]\n",
        "\n",
        "\n",
        "# Only include if predicted 1 and \"an\" or \"culex\"\n",
        "y_dev_n = []\n",
        "genera_dev = []\n",
        "index = []\n",
        "\n",
        "for i in range(len(y_dev)):\n",
        "    genus = specs_dev[i].partition(' ')[0]\n",
        "    cat = y_pred[i]\n",
        "    if cat:\n",
        "        if genus == \"an\":\n",
        "            index.append(True)\n",
        "            y_dev_n.append(0)\n",
        "            genera_dev.append(\"anopheles\")\n",
        "        elif genus == \"culex\":\n",
        "            index.append(True)\n",
        "            y_dev_n.append(1)\n",
        "            genera_dev.append(\"culex\")\n",
        "        else:\n",
        "            index.append(False)\n",
        "    else:\n",
        "        index.append(False)\n",
        "\n",
        "X_dev_n = X_dev[index]\n",
        "y_train_n = np.array(y_train_n)\n",
        "y_dev_n = np.array(y_dev_n)\n",
        "model = tf.keras.models.clone_model(comp_model)\n",
        "\n",
        "print(\"----Training----\")\n",
        "print(\"Culex Clips: \", np.count_nonzero(y_train_n))\n",
        "print(\"Anopheles Clips: \", len(y_train_n)-np.count_nonzero(y_train_n))\n",
        "print(\"Total: \", len(y_train_n), '\\n')\n",
        "\n",
        "print(\"----Dev----\")\n",
        "print(\"Culex Clips: \", np.count_nonzero(y_dev_n))\n",
        "print(\"Anopheles Clips: \", len(y_dev_n)-np.count_nonzero(y_dev_n))\n",
        "print(\"Total: \", len(y_dev_n), '\\n')"
      ],
      "metadata": {
        "id": "m4lo9ALDsxPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor=\"val_loss\",\n",
        "                                patience=10,\n",
        "                                verbose=1,\n",
        "                                restore_best_weights=True)\n",
        "run_logdir = get_run_logdir(name=\"find_the_species\")  # e.g., my_logs/run_2022_08_01_17_25_59\n",
        "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir,\n",
        "                                                profile_batch=(100, 200))\n",
        "history = model.fit(X_train_n, y_train_n, epochs=100,\n",
        "                    validation_data=(X_dev_n, y_dev_n),\n",
        "                    callbacks=[tensorboard_cb])"
      ],
      "metadata": {
        "id": "Zl5phgsC3Xh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evalute model performance\n",
        "\n",
        "y_pred_n = model.predict(X_dev_n)\n",
        "\n",
        "# Plotting of ROC curve\n",
        "y_prob_n = 1 / (1 + np.exp(-y_pred_n))\n",
        "y_prob_n = y_prob_n.flatten()\n",
        "y_pred_n = y_prob_n.round().astype(int)\n",
        "RocCurveDisplay.from_predictions(y_dev_n, y_prob_n)\n",
        "plt.show()\n",
        "\n",
        "correct = y_pred_n == y_dev_n\n",
        "\n",
        "correctly_classified_images = X_dev_n[correct]\n",
        "incorrectly_classified_images = X_dev_n[~correct]\n",
        "print(\"\")\n",
        "print(\"----RESULTS----\")\n",
        "print(\"Correct: \", len(correctly_classified_images))\n",
        "print(\"Incorrect: \", len(incorrectly_classified_images))\n",
        "\n",
        "true_labels = y_dev_n[~correct].astype(int)\n",
        "predicted_labels = y_pred_n[~correct]\n",
        "\n",
        "# Display first 10 incorrectly classified images\n",
        "display_images(incorrectly_classified_images, true_labels, predicted_labels,\n",
        "                num_images=min(25, len(incorrectly_classified_images)))\n",
        "\n",
        "confusion = confusion_matrix(y_dev_n, y_pred_n)\n",
        "true_pos = confusion[1][1]\n",
        "true_neg = confusion[0][0]\n",
        "false_pos = confusion[0][1]\n",
        "false_neg = confusion[1][0]\n",
        "\n",
        "print(\"True positive: \" + str(true_pos))\n",
        "print(\"True negative: \" + str(true_neg))\n",
        "print(\"False positive: \" + str(false_pos))\n",
        "print(\"False negative: \" + str(false_neg))\n",
        "\n",
        "sensitivity = (true_pos/(true_pos+false_neg)).round(3)\n",
        "specificity = (true_neg/(true_neg+false_pos)).round(3)\n",
        "\n",
        "print(\"Sensitivity: \" + str(sensitivity))\n",
        "print(\"Specificity: \" + str(specificity))\n",
        "print(\"Score: \" + str((sensitivity+specificity).round(3)))\n",
        "disp = ConfusionMatrixDisplay(confusion,\n",
        "                                display_labels=[\"Anopheles\", \"Culex\"])\n",
        "disp.plot()"
      ],
      "metadata": {
        "id": "uAONXKOi4BWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyse results"
      ],
      "metadata": {
        "id": "YEAj1obOnitR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=./drive/MyDrive/my_logs"
      ],
      "metadata": {
        "id": "sM6YeGvMIOUM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1xySUVG-y98J7m9yTBi9nKEKWuGa74gSt",
      "authorship_tag": "ABX9TyPH8vcFjBcNruoH2+7FJL3E",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}